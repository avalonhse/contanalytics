{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "This is a small tutorial which helps you get started with the competition on Kaggle: Dogs vs Cats (http://www.kaggle.com/c/dogs-vs-cats)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 1: Download data files:\n",
      "   \n",
      "- sampleSubmission.csv: standard format file to submit on Kaggle\n",
      "- test1.zip: test data contains 12,500 images\n",
      "- train.zip: train data contains 25,000 images\n",
      "\n",
      "Your work here is train your algorithm on these files and predict the labels for test1.zip (1 = dog, 0 = cat)\n",
      "\n",
      "Note:\n",
      "\n",
      "Some places in the code you found: os.chdir(\"path\"). It is used to set your working directory. To run the code, you have to replace the \"path\" in my code with \"path\" is your current directory such as:\n",
      "\n",
      "os.chdir(\"your path/sparse_auto_encoder/train50\")"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 2: Resize your images with the same size (200 x 200, 300 x 300, ...) on your train and test set.\n",
      "Here I use the train and test set with size 50 x 50."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 3: Create data from train set. (save it in the variable called \"data\" and save it to file \"data50.csv\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create data & data.csv\n",
      "import csv\n",
      "import time\n",
      "\n",
      "# Start the clock\n",
      "start = time.clock()\n",
      "\n",
      "import os\n",
      "os.getcwd()\n",
      "\n",
      "# set your working directory\n",
      "os.chdir(\"/home/trinhdoan/sparse_auto_encoder/train50\")\n",
      "\n",
      "# import lib to load and resize image\n",
      "import PIL\n",
      "from PIL import Image\n",
      "\n",
      "\n",
      "data = []\n",
      "\n",
      "# write cat data\n",
      "for i in range(12500):\n",
      "    img = Image.open(\"catResize.\" + str(i) + \".jpg\")\n",
      "    pixel = img.load()\n",
      "    w, h = img.size\n",
      "    all_pixel = []\n",
      "    for x in range(w):\n",
      "        for y in range(h):\n",
      "            cpixel = pixel[x,y]\n",
      "            gray = (int)((0.3 * cpixel[0]) + (0.59 * cpixel[1]) + (0.11 * cpixel[2]))\n",
      "            all_pixel.append(gray)\n",
      "\n",
      "    data.append(all_pixel)\n",
      "  \n",
      "# write dog data\n",
      "for i in range(12500):\n",
      "    img = Image.open(\"dogResize.\" + str(i) + \".jpg\")\n",
      "    pixel = img.load()\n",
      "    w, h = img.size\n",
      "    all_pixel = []\n",
      "    for x in range(w):\n",
      "        for y in range(h):\n",
      "            cpixel = pixel[x,y]\n",
      "            gray = (int)((0.3 * cpixel[0]) + (0.59 * cpixel[1]) + (0.11 * cpixel[2]))\n",
      "            all_pixel.append(gray)\n",
      "\n",
      "    data.append(all_pixel)\n",
      "\n",
      "    \n",
      "os.chdir(\"/home/trinhdoan/sparse_auto_encoder/\")   \n",
      "f = open(\"data50.csv\", \"wb\") # can use f = open(\"data50.csv\", \"w\")\n",
      "writer = csv.writer(f)\n",
      "writer.writerows(data)\n",
      "\n",
      "# Stop the clock\n",
      "elapsed = (time.clock() - start)\n",
      "print \"Processing time:\" +  str(elapsed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing time:58.61\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 4: Train your data with the autoencoder "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train data to take W1, W2, b1, b2\n",
      "\n",
      "# start the clock\n",
      "start = time.clock()\n",
      "\n",
      "import utils\n",
      "import numpy as np\n",
      "import scipy.optimize\n",
      "import struct\n",
      "import sac\n",
      "import pickle\n",
      "\n",
      "data = np.array(data)\n",
      "data = data.T\n",
      "\n",
      "file = open(\"label.csv\")\n",
      "label = []\n",
      "\n",
      "for line in file:\n",
      "    label.append(line)\n",
      "\n",
      "patches = data\n",
      "visible_size = 50*50\n",
      "hidden_size = 196\n",
      "options = sac.SparseAutoEncoderOptions(visible_size,\n",
      "                                       hidden_size,\n",
      "                                       output_dir=\"output_train_data50\",\n",
      "                                       max_iterations = 400)\n",
      "network = sac.SparseAutoEncoder(options, patches)\n",
      "\n",
      "answer = network.learn()\n",
      "\n",
      "\n",
      "\n",
      "f = sac.SparseAutoEncoder(options, patches)\n",
      "\n",
      "a2, a3 = f.feed_forward(data, answer.W1, answer.W2, answer.b1, answer.b2)\n",
      "\n",
      "\n",
      "# stop the clock\n",
      "elapsed = (time.clock() - start)\n",
      "print \"Processing time: \" + str(elapsed/60) + \" mins.\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to  output_train_data50/w1frame000.png\n",
        "Saving to "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " output_train_data50/w2frame000.png\n",
        "Saving to "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " output_train_data50/network.png\n",
        "Processing time: 291.747 mins."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "196\n",
        "25000\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 5: Build model with SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start the clock\n",
      "start = time.clock()\n",
      "\n",
      "#  train a2 (of train data)  with SVM\n",
      "from sklearn import svm\n",
      "svm_alg = svm.LinearSVC()\n",
      "svm_alg.fit(a2.T, label) \n",
      "\n",
      "\n",
      "# stop the clock\n",
      "elapsed = (time.clock() - start)\n",
      "print \"Processing time: \" + str(elapsed/60) + \" mins.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing time: 0.385666666667 mins.\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 6: Create data from test set. (save it to variable called \"test\" and file \"test50.csv\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start the clock\n",
      "start = time.clock()\n",
      "\n",
      "import os\n",
      "os.chdir(\"/home/trinhdoan/sparse_auto_encoder/test50\")\n",
      "\n",
      "test = []\n",
      "\n",
      "for i in range(1, 12501):\n",
      "    img = Image.open(\"test\" + str(i) + \".jpg\")\n",
      "    pixel = img.load()\n",
      "    w, h = img.size\n",
      "    all_pixel = []\n",
      "    for x in range(w):\n",
      "        for y in range(h):\n",
      "            cpixel = pixel[x, y]\n",
      "            gray = (int)((0.3 * cpixel[0]) + (0.59 * cpixel[1])+ (0.11 * cpixel[2]))\n",
      "            all_pixel.append(gray)\n",
      "    test.append(all_pixel)\n",
      "    \n",
      "os.chdir(\"/home/trinhdoan/sparse_auto_encoder/\")   \n",
      "f = open(\"test50.csv\", \"wb\")\n",
      "writer = csv.writer(f)\n",
      "writer.writerows(test)\n",
      "\n",
      "# Stop the clock\n",
      "\n",
      "elapsed = (time.clock() - start)\n",
      "print \"Processing time:\" +  str(elapsed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing time:28.57\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = np.array(test)\n",
      "test = test.T\n",
      "# test data is done here\n",
      "# transpose \"test\" to match the input format of autoencoder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 7: Test process with \"test\" data with autoencoder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# feature extraction from test set\n",
      "\n",
      "# start the clock\n",
      "start = time.clock()\n",
      "\n",
      "import utils\n",
      "import numpy as np\n",
      "import scipy.optimize\n",
      "import struct\n",
      "import sac\n",
      "import pickle\n",
      "\n",
      "\n",
      "patches = test\n",
      "visible_size = 50*50\n",
      "hidden_size = 196\n",
      "options = sac.SparseAutoEncoderOptions(visible_size,\n",
      "                                       hidden_size,\n",
      "                                       output_dir=\"output_test50\",\n",
      "                                       max_iterations = 400)\n",
      "network = sac.SparseAutoEncoder(options, patches)\n",
      "\n",
      "\n",
      "a2_test, a3_test = network.feed_forward(test, answer.W1, answer.W2, answer.b1, answer.b2)\n",
      "\n",
      "\n",
      "# stop the clock\n",
      "elapsed = (time.clock() - start)\n",
      "print \"Processing time: \" + str(elapsed/60) + \" mins.\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing time: 0.572166666667 mins.\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 8: Making prediction with SVM with feature from the test above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make predictions to test data\n",
      "predictions = svm_alg.predict(a2_test.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Step 9: Write your predictions to the csv file with right format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write file to submit on Kaggle\n",
      "fi = open(\"output.csv\", \"w\")\n",
      "\n",
      "fi.write(\"id,label\\n\")\n",
      "index = 1\n",
      "for p in predictions:\n",
      "    fi.write(str(index))\n",
      "    fi.write(\",\")\n",
      "    fi.write(str(p))\n",
      "    index += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}